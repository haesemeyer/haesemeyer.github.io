---
layout: default
---
{% include image.html
    img="assets/img/PerceptionExample.png"
    title="PerceptionExample"
    width="450"
    caption="From sensory perception to (in)action" %}

Whether we are crossing the street or evaluating the temperature of our drink our brain
constantly senses the environment, processes relevant information and hopefully produces
appropriate reactions to the environment. This feat relies on the coordinated interplay of many critical building blocks. Sensory 
organs such as our eyes or temperature receptors in our skin need to detect features of
our surroundings. This information has to be accurately relayed to our brain which then
integrates the sensory information to "make sense of it all". At the same time the meaning of sensory input is not absolute. A desirable temperature
for a cup of coffee is generally not considered appropriate for a glass of beer. Similarly
strategies for crossing a street differ whether traffic runs on the right or left. The brain
therefore needs to take context into account when processing sensory cues.

It is my overall goal to understand how groups of neurons in the brain interact to encode
and interpret information about the world in order to generate appopriate behaviors.

To this end I am using larval zebrafish as a model system. Due to its transparency and small size this vertebrate model allows all optical access to the entire brain. This creates the unique opportunity of identifying brain regions that are relevant for a task in an unbiased manner. I subsequently use quantitative modeling to fully characterize how the brain encodes sensory stimuli and how it creates adaptive behaviors. **These quantitative circuit models form an important step towards understanding computation as they generate testable hypotheses of how neural circuits process information**. *See [research](/research/) for details.*
